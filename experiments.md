# Описание проведённых экспериментов

Для выбора оптимальной модели были проведены различные эксперименты с параметрами обучения, их результаты будут представлены ниже.

### Модель, использующая оптимизатор Adam:

![](exp_images/ADAM_acc.png)
![](exp_images/ADAM_loss.png)

### Модель со 128 нейронами в полносвязном слое:

![](exp_images/128n_acc.png)
![](exp_images/128m_loss.png)

### Модель с 512 нейронами в полносвязном слое:

![](exp_images/512n_acc.png)
![](exp_images/512n_loss.png)

### Модель с двойным размер свёрточных ядер (относительно тех, которые используются на данный момент) + Adam:

![](exp_images/ADAM_kernel2x_acc.png)
![](exp_images/ADAM_Kernel2x_loss.png)

### Модель с двойным размер свёрточных ядер (относительно тех, которые используются на данный момент) + Adam + 512 нейронов:

![](exp_images/512n+4x+Adam_acc.png)
![](exp_images/512n+4x+Adam_loss.png)

### Вывод

При увеличении производственных мощностей можно продолжить увеличивать количество нейронов с оптимизатором Adam, есть все предположения считать, что это повысит точность классификации.
